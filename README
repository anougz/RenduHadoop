# **TD1: Hadoop**
# **3. ZAZA**
## 3.1. Prise en main Commandes HDFS
**Quelle est la différence ?**
````
hadoop fs et hdfs dfs
````
Les résultats des commandes sont les mêmes. Cependant, hdfs dfs est une commande plus récente pour les dernières versions.

**Quelle est la version hadoop de sandbox 2.6.5?**
```
hadoop version
```
La version est 2.5.0

## 3.2. Importer et exporter des données
**Quel est le résultat obtenu? Commentez!**
````
hdfs dfs -ls
hdfs dfs -ls/
````
Réponse : Rien n'est renvoyé pour la première. La seconde renvoie la liste des fichiers dans ls.

**Quelle est la commande pour lire le contenue de /user?** 
```
hdfs dfs -ls /user
```

**Que ce passe-il si vous refaites toute les commandes précedentes avec hadoop fs au lieux de hdfs dfs?**

Réponse : Rien ne change, la commande est la même.

**Sachant que vous êtes en ligne de commande décrivez ce que vous avez fait**

Réponse : Pour créer le fichier en local on utilise la commande suivante
````
hadoop fs -touchz /user/monfichier.txt
Found 16 items
drwxr-xr-x   - admin     hdfs            0 2018-06-18 14:52 /user/admin
drwxrwx---   - ambari-qa hdfs            0 2018-06-18 14:52 /user/ambari-qa
drwxr-xr-x   - amy_ds    hdfs            0 2018-06-18 14:53 /user/amy_ds
drwxr-xr-x   - root      hdfs            0 2018-06-18 14:52 /user/anonymous
drwxr-xr-x   - druid     hadoop          0 2018-06-18 16:06 /user/druid
drwxr-xr-x   - hbase     hdfs            0 2018-06-18 15:08 /user/hbase
drwxr-xr-x   - hcat      hdfs            0 2018-06-18 15:12 /user/hcat
drwxr-xr-x   - hive      hdfs            0 2018-06-18 15:18 /user/hive
drwxrwxr-x   - livy      hdfs            0 2018-06-18 15:11 /user/livy
drwxr-xr-x   - maria_dev hdfs            0 2018-06-18 14:52 /user/maria_dev
-rw-r--r--   1 maria_dev hdfs            0 2024-03-26 11:26 /user/monfichier.txt
drwxrwxr-x   - oozie     hdfs            0 2018-06-18 16:08 /user/oozie
drwxr-xr-x   - raj_ops   hdfs            0 2018-06-18 14:53 /user/raj_ops
drwxr-xr-x   - root      hdfs            0 2018-06-18 14:52 /user/root
drwxrwxr-x   - spark     hdfs            0 2018-06-18 15:10 /user/spark
drwxr-xr-x   - zeppelin  hdfs            0 2018-06-18 15:10 /user/zeppelin
````

**Si vous voulez envoyer vos données vers HDFS sans garder une copie en local : Quelle est la commande a effectuer ?**
Réponse : 
```
hdfs dfs -moveFromLocal monfichier.txt
```

## 3.3. Manipulation des données dans HDFS
**Completez la commande ci-dessous:**
```
hadoop fs -cat /user/monfichier.txt
```
**Completez la commande ci-dessous:**
```
/hadoop fs -rm /user/monfichier.txt
```

**Créez localement un dossier nommé data et envoyez-le sur HDFS.**
````
hadoop fs -mkdir /user/data
````

**Créez un dossier datasets dans le dossier data, puis déplacez monfichier.txt dans datasets à l’aide de la commande -mv, décrivez vos commandes.**

````
hadoop fs -mv /user/monfichier.txt /user/data/datasets/
````

**Créer une copie de monfichier.txt dans le répertoire data sous le nom copiedemonfichier.txt.**
```
hadoop fs -cp /user/data/monfichier.txt /user/data/copiedemonfichier.tx
```

**Si on veut supprimer un répertoire depuis le système de fichiers HDFS. Quelle est la commande à executer?**
````
hadoop fs -rm -r
````
L'option -r permet de supprimer le repertoire et les sous repertoires.
Exemple pour supprimer le répertoire "datasets" dans le répertoire "data" :
````
hadoop fs -rm -r /user/data/datasets
````

**Une commande qui vous permet de voir « l’état de santé » de votre HDFS (elle vérifie les incohérences : blocks manquants, nom de réplicas insufusants,…) : hdfs fsck /user. Décrivez le résultat obtenu**
````
hdfs fsck /user
````

Résultats :
````
Connecting to namenode via http://sandbox-hdp.hortonworks.com:50070/fsck?ugi=maria_dev&path=%2Fuser
FSCK started by maria_dev (auth:SIMPLE) from /172.18.0.2 for path /user at Tue Mar 26 12:49:06 UTC 2024
....................................................................................................
Status: HEALTHY
 Total size:    976496335 B
 Total dirs:    48
 Total files:   995
 Total symlinks:                0
 Total blocks (validated):      992 (avg. block size 984371 B)
 Minimally replicated blocks:   992 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    1
 Average block replication:     1.0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Number of data-nodes:          1
 Number of racks:               1
FSCK ended at Tue Mar 26 12:49:06 UTC 2024 in 720 milliseconds


The filesystem under path '/user' is HEALTHY
````
Notre système est en bonne santé, rien à signaler.

## **3.4. Manipulation de fichiers télécharger depuis un serveur**

**Si il y'a une erreur va apparaitre, décrivez comment vous avez pu faire pour télécharger le fichier.(Commentez la raison pour laqeulle l'erreur a lieu)**
````
wget https://files.grouplens.org/datasets/movielens/ml-1m.zip
````
Résultats : 
````
2024-03-26 12:57:38 (3.66 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]
````
Pour décompresser le fichier zip :
````
unzip ml-1m.zip
````

**Créez un répértoire /datasets/movies en local et sur hdfs**
````
mkdir C:\Users\anougarou\Documents\bigdata\datasets\
mkdir C:\Users\anougarou\Documents\bigdata\datasets\movies
````

**Déroulez les étapes de création des deux dossier /datasets/movies et la copie du fichier rating.dat à partir du système local vers HDFS (dans movies).**

Pour créer le répertoire "movies" dans HDFS
L'option -p est utilisée pour créer récursivement les répertoires parents.
````
hadoop fs -mkdir -p /user/datasets/movies
````
Pour la copie du fichier "ratings.dat" de le système local vers HDFS dans le répertoire "movies" :
````
hadoop fs -copyFromLocal C:/Users/anougarou/Documents/bigdata/datasets/movies/ratings.dat /user/datasets/movies
````

**Affichez combien de blocs occupe le fichier avec la commande hdfs fsck [chemin vers votre fichier] -files -blocks (Commentez!)**
````
hdfs fsck /user/datasets/movies/rating.dat -files -blocks
````
## 3.5. Fichiers de configuration HDFS
